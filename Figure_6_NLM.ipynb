{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-244a20a3-5850-49a8-b3c4-47c8dd90e3f4",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "# AM207 Final Project\n",
    "\n",
    "Paper: *Learned Uncertainty-Aware (LUNA) Bases for Bayesian Regression using Multi-Headed Auxiliary Networks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is for an elaine problem:\n",
    "import sys\n",
    "sys.path.append('/Users/elainecunha/opt/anaconda3/envs/py3.8/lib/python3.8/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00001-82b15dd3-3681-4233-b273-015b39362a48",
    "deepnote_cell_type": "code",
    "execution_millis": 0,
    "execution_start": 1607622678968,
    "output_cleared": false,
    "source_hash": "7ff14c81",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from autograd import numpy as np\n",
    "from autograd import grad\n",
    "from autograd.misc.optimizers import adam, sgd\n",
    "from autograd import scipy as sp\n",
    "import autograd.numpy.random as npr\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# our libraries\n",
    "import utils\n",
    "from nlm import NLM\n",
    "from feed_forward import Feedforward\n",
    "import bayes_helpers as bh\n",
    "\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-3de52f4a-e308-4308-bb56-64301fc72795",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00002-da662230-83a9-4a83-a071-abb21b920110",
    "deepnote_cell_type": "code",
    "execution_millis": 7,
    "execution_start": 1607622680831,
    "output_cleared": false,
    "source_hash": "d822ff03",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training data\n",
    "x_train, y_train, x_test = utils.generate_data(training_seed)\n",
    "\n",
    "# for model evaluation: computing log likelihood\n",
    "x_valid, y_valid, x_test_not_used = utils.generate_data(valid_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00008-3ff41d87-f57f-4dfb-a174-cde811f0ea9a",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Train NLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00005-3b5e8825-04a1-4a79-80e0-44a0bbabf7d5",
    "deepnote_cell_type": "code",
    "execution_millis": 529103,
    "execution_start": 1607622858999,
    "output_cleared": false,
    "source_hash": "d851cdec",
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt_params[\"max_iteration\"] = real_max_iteration\n",
    "# train NLMs\n",
    "reg_params = [0.01, 0.1, 1.0,10]\n",
    "nlms = []\n",
    "log_ls = []\n",
    "\n",
    "for i,r in enumerate(reg_params):\n",
    "\n",
    "    # append model to list of NLMs\n",
    "    nlms.append(NLM(prior_variance,y_noise_variance, r, nlm_architecture, random_seed))\n",
    "    \n",
    "    # train model\n",
    "    t0 = time.time()\n",
    "    nlms[i].train(x_train, y_train, opt_params)\n",
    "    nlm_time = np.round(time.time() - t0, 3)\n",
    "    log_ls.append(nlms[i].get_log_l(x_train,y_train,x_valid,y_valid))\n",
    "    \n",
    "    print('Model {}: {} seconds'.format(i, nlm_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Posterior and Prior Predictives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00011-1e248a0b-2711-4319-a408-190b228796be",
    "deepnote_cell_type": "code",
    "execution_millis": 52,
    "execution_start": 1607623388108,
    "output_cleared": false,
    "source_hash": "c1a17f3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate posterior and prior predictives\n",
    "post_pred_mean = []\n",
    "post_pred_upper = []\n",
    "post_pred_lower = []\n",
    "prior_predictive_samples = []\n",
    "\n",
    "for model in nlms:\n",
    "    \n",
    "    # get posterior and prior samples\n",
    "    post_pred, post_pred_samples = model.predict(x_test, prior=False)\n",
    "    prior_pred, prior_pred_samples = model.predict(x_test, prior=True)\n",
    "\n",
    "    # calculate posterior predictive mean\n",
    "    pp_mean = np.mean(post_pred_samples, axis=0)\n",
    "    pp_upper = np.percentile(post_pred_samples, 97.5, axis=0)\n",
    "    pp_lower = np.percentile(post_pred_samples, 2.5, axis=0)\n",
    "\n",
    "    # store results\n",
    "    post_pred_mean.append(pp_mean)\n",
    "    post_pred_upper.append(pp_upper)\n",
    "    post_pred_lower.append(pp_lower)\n",
    "    prior_predictive_samples.append(prior_pred_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate ground truth line\n",
    "f = lambda x: (x**3)\n",
    "x_true = np.linspace(-10, 10, 100)\n",
    "y_true = f(x_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00013-77503acf-56de-41d3-a8b5-cdbfb92155f6",
    "deepnote_cell_type": "code",
    "execution_millis": 2,
    "execution_start": 1605905735712,
    "output_cleared": false,
    "source_hash": "b623e53d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "num_figures = len(nlms)\n",
    "\n",
    "fig,ax = plt.subplots(num_figures, 2, figsize=(10,20))\n",
    "\n",
    "for i,model in enumerate(nlms):\n",
    "    ax[i][0].scatter(x_train, y_train, color='red')\n",
    "    ax[i][1].scatter(x_train, y_train, color='red')\n",
    "    ax[i][0].plot(x_true, y_true, color='black')\n",
    "    ax[i][1].plot(x_true, y_true, color='black')\n",
    "    ax[i][1].plot(x_test.flatten(), post_pred_mean[i], color='blue')\n",
    "    ax[i][1].fill_between(x_test.flatten(), post_pred_upper[i], post_pred_lower[i], color='blue', alpha=0.1, label='95% Pred. Interval') \n",
    "\n",
    "    for j in range(prior_predictive_samples[i].shape[1]):\n",
    "        \n",
    "        ax[i][0].plot(x_test.flatten(), prior_predictive_samples[i][j,:], alpha = 0.1, color='blue')\n",
    "\n",
    "    ax[i][0].axis([-5, 5, -150, 150])\n",
    "    ax[i][1].axis([-5, 5, -150, 150])\n",
    "    ax[i][0].set_title('Prior Predictive, reg_param={}'.format(reg_params[i]))\n",
    "    ax[i][1].set_title(f'Posterior Predictive, reg_param={reg_params[i]} \\n Log Likelihood {round(log_ls[i],3)}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "bd9b06a9-900b-4258-b9d3-f28f55059097",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
