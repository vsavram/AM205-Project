{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00001-95841569-0783-4946-95fc-911db545dd64",
    "deepnote_cell_type": "code",
    "execution_millis": 1798,
    "execution_start": 1606948460930,
    "output_cleared": false,
    "source_hash": "69f8c1eb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import standard libraries\n",
    "#!pip install autograd\n",
    "from autograd import numpy as np\n",
    "from autograd import grad\n",
    "from autograd.misc.optimizers import adam, sgd\n",
    "from autograd import scipy as sp\n",
    "import autograd.numpy.random as npr\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "# import our libraries\n",
    "import bayes_helpers as bh\n",
    "from utils import generate_data\n",
    "from utils import run_toy_nn\n",
    "from feed_forward import Feedforward\n",
    "from nlm import NLM\n",
    "\n",
    "from optimizers import *\n",
    "from config import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test = generate_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the NLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bayes_helpers as bh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iteration 0 lower bound 614579.0109162953; gradient mag: 1271928.6484876384"
     ]
    }
   ],
   "source": [
    "nn = Feedforward(nlm_architecture, random=random_seed)\n",
    "\n",
    "t0 = time.time()\n",
    "nn.fit(x_train, y_train, opt_params)\n",
    "nn_time = np.round(time.time() - t0, 3)\n",
    "\n",
    "mse = nn.objective_trace.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a function that returns the objective trace for a list of optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that produces the objective trace for each optimizer\n",
    "def compute_objective_trace(nlm, optimizer_list):\n",
    "    \n",
    "    # Initialize a list used to store the objective traces and number of iterations\n",
    "    objective_trace_list,num_iterations_list = [],[]\n",
    "    \n",
    "    # Iterate over each optimizer\n",
    "    for optimizer_function in optimizer_list:\n",
    "\n",
    "        # Set the parameters\n",
    "        params = {'max_iteration':2000, \n",
    "                  'random_restarts':3,\n",
    "                  'optimizer': optimizer_function}\n",
    "\n",
    "        # Fit the NLM to the training set\n",
    "        nlm.train(x_train, y_train, params)\n",
    "        # Pull the objective trace\n",
    "        trace = nlm.ff.objective_trace\n",
    "        \n",
    "        objective_trace_list.append(trace)\n",
    "        num_iterations_list.append(len(trace))\n",
    "        \n",
    "    return objective_trace_list,num_iterations_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute the objective trace for each optimizer\n",
    "optimizer_list = [steepest_descent, BFGS, conjugate_gradient]\n",
    "objective_trace_list,num_iterations_list = compute_objective_trace(nlm, optimizer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the objective trace for each optimizer\n",
    "fig, axes = plt.subplots(1,3,figsize = (18,8))\n",
    "ax = axes.flatten()\n",
    "ax[0].plot(np.arange(0,num_iterations_list[0],1), objective_trace_list[0], 'black', label='steepest')\n",
    "ax[0].set_xlabel('Iteration', fontsize = 14)\n",
    "ax[0].set_ylabel('MSE', fontsize = 14)\n",
    "ax[0].set_title('MSE Score vs Iteration', fontsize = 18)\n",
    "ax[0].legend(fontsize=12);\n",
    "ax[1].plot(np.arange(0,num_iterations_list[1],1), objective_trace_list[1], 'blue', label='BFGS')\n",
    "ax[1].set_xlabel('Iteration', fontsize = 14)\n",
    "ax[1].set_ylabel('MSE', fontsize = 14)\n",
    "ax[1].set_title('MSE Score vs Iteration', fontsize = 18)\n",
    "ax[1].legend(fontsize=12);\n",
    "ax[2].plot(np.arange(0,num_iterations_list[2],1), objective_trace_list[2], 'red', label='conjugate')\n",
    "ax[2].set_xlabel('Iteration', fontsize = 14)\n",
    "ax[2].set_ylabel('MSE', fontsize = 14)\n",
    "ax[2].set_title('MSE Score vs Iteration', fontsize = 18)\n",
    "ax[2].legend(fontsize=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the objective trace for each optimizer (the first 20 iterations are removed)\n",
    "fig, axes = plt.subplots(1,3,figsize = (18,8))\n",
    "ax = axes.flatten()\n",
    "ax[0].plot(np.arange(20,num_iterations_list[0],1), objective_trace_list[0][20:], 'black', label='steepest')\n",
    "ax[0].set_xlabel('Iteration', fontsize = 14)\n",
    "ax[0].set_ylabel('MSE', fontsize = 14)\n",
    "ax[0].set_title('MSE Score vs Iteration', fontsize = 18)\n",
    "ax[0].legend(fontsize=12);\n",
    "ax[1].plot(np.arange(20,num_iterations_list[1],1), objective_trace_list[1][20:], 'blue', label='BFGS')\n",
    "ax[1].set_xlabel('Iteration', fontsize = 14)\n",
    "ax[1].set_ylabel('MSE', fontsize = 14)\n",
    "ax[1].set_title('MSE Score vs Iteration', fontsize = 18)\n",
    "ax[1].legend(fontsize=12);\n",
    "ax[2].plot(np.arange(20,num_iterations_list[2],1), objective_trace_list[2][20:], 'red', label='conjugate')\n",
    "ax[2].set_xlabel('Iteration', fontsize = 14)\n",
    "ax[2].set_ylabel('MSE', fontsize = 14)\n",
    "ax[2].set_title('MSE Score vs Iteration', fontsize = 18)\n",
    "ax[2].legend(fontsize=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00008-bd0b2e89-1b52-4756-8bbb-03afb90b5f1b",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "33298fe9-5c82-4b2a-b4a6-8b8f00fdd090",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
