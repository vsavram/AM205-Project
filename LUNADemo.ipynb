{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-bf4f5e8c-e6ce-457c-a9f7-a3b9e394f734",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "TODOS\n",
    " - add non-NLM neural net to compare against as well\n",
    " - normalize X and Y before tuning\n",
    " - try tanh activation\n",
    " - send nlm implementation to cooper with all hyperparameters\n",
    " - decomposing nlm final output and bayesian conf intervals\n",
    " - hyperparameter tuning is too specific to each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00001-c8e2dae6-b4b8-4ffb-a2ea-84c5c3269b13",
    "deepnote_cell_type": "code",
    "execution_millis": 1227,
    "execution_start": 1607545561519,
    "output_cleared": false,
    "source_hash": "8c29d073",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import standard libraries\n",
    "from autograd import numpy as np\n",
    "from autograd import grad\n",
    "from autograd.misc.optimizers import adam, sgd\n",
    "from autograd import scipy as sp\n",
    "import autograd.numpy.random as npr\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# import our libraries\n",
    "import bayes_helpers as bh\n",
    "from utils import generate_data, run_toy_nn\n",
    "from feed_forward import Feedforward\n",
    "from nlm import NLM\n",
    "from luna import LUNA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-eb8e53a0-817c-4aec-9943-931248ffc58c",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "### Generate Cubic Dataset\n",
    "\n",
    "Generates 100 datapoints for train and 100 points for test according to the function\n",
    "\n",
    "$$y = \\frac{1}{2}x^3 + \\epsilon$$\n",
    "\n",
    "$$\\epsilon \\sim N(0, 3^2)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00004-849fb954-2d0d-4439-8d0d-1f9e85724789",
    "deepnote_cell_type": "code",
    "execution_millis": 0,
    "execution_start": 1607545562808,
    "output_cleared": false,
    "source_hash": "189029f4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_test = generate_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-fff6b3d1-9ca1-4ef2-b5a9-16a3e221bb45",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "### Define Hyperameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00004-3e33c837-e900-464d-83ae-4a9309a0ef86",
    "deepnote_cell_type": "code",
    "execution_millis": 1,
    "execution_start": 1607545572232,
    "output_cleared": false,
    "source_hash": "cbc0f147",
    "tags": []
   },
   "outputs": [],
   "source": [
    "####  activation ####\n",
    "activation_fn_type = 'relu'\n",
    "activation_fn = lambda x: np.maximum(np.zeros(x.shape), x)\n",
    "\n",
    "#### LUNA NN structure ####\n",
    "width = 5\n",
    "hidden_layers = 2\n",
    "input_dim = 1\n",
    "output_dim = 5 #number of auxiliary functions\n",
    "architecture = {'width': width,\n",
    "            'hidden_layers': hidden_layers,\n",
    "            'input_dim': input_dim,\n",
    "            'output_dim': output_dim,\n",
    "            'activation_fn_type': activation_fn_type,\n",
    "            'activation_fn_params': 'rate=1',\n",
    "            'activation_fn': activation_fn}\n",
    "\n",
    "#### optimization parameters ####\n",
    "step_size = 1e-3\n",
    "num_iterations = 500\n",
    "\n",
    "optimization_params = {'step_size':step_size, \n",
    "          'max_iteration':num_iterations, \n",
    "          'random_restarts':1,\n",
    "          'optimizer':'adam'}\n",
    "\n",
    "#### objective function parameters ####\n",
    "\n",
    "regularization_param_nlm = 8.37 #they chose this in the paper, what a beautifully specific number\n",
    "\n",
    "# in the paper they searched over 1e-3,...,1e3 and chose 1e-1 for regularization\n",
    "\n",
    "regularization_param_luna = 1e-1\n",
    "\n",
    "# in the paper they searched over 1e-3,...,1e3 and chose 1e0 for similarity\n",
    "\n",
    "similarity_param = 1e0\n",
    "\n",
    "#### other parameters ####\n",
    "prior_variance = 1 # chosen in the paper. declared \"reasonable\". who decided this\n",
    "y_noise_variance = 9 # needs to match what the dataset itself is\n",
    "random = np.random.RandomState(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00006-b1ea0118-8f50-4f06-83f5-e141bfb33d0a",
    "deepnote_cell_type": "code",
    "execution_millis": 39360,
    "execution_start": 1607545574991,
    "output_cleared": false,
    "source_hash": "94272f74",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iteration 400 lower bound 140335.10020276246; gradient mag: 70076.01892199571\n",
      "Done Training\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "nlm = NLM(prior_variance,y_noise_variance, regularization_param_nlm, architecture, random)\n",
    "nlm.train(x_train,y_train, optimization_params)\n",
    "nlm_time = np.round(time.time() - t0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00005-3077264e-dc34-4937-9e4a-516ae76a3360",
    "deepnote_cell_type": "code",
    "execution_millis": 3583065,
    "execution_start": 1607545614355,
    "output_cleared": false,
    "source_hash": "b31a2d01",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iteration 300 lower bound 1570.619045530601; gradient mag: 339.14883310186026"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "luna = LUNA(prior_variance, y_noise_variance, regularization_param_luna, similarity_param, architecture, random)\n",
    "luna.train(x_train, y_train, optimization_params)\n",
    "luna_time = np.round(time.time() - t0, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00006-5384b707-ecdc-49fb-9837-8eaac56ed226",
    "deepnote_cell_type": "code",
    "execution_millis": 942,
    "execution_start": 1607552662223,
    "output_cleared": false,
    "source_hash": "2c332e75",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### predict on the test x-values ####\n",
    "nlm_posterior_predictions, nlm_posterior_predictive_samples = nlm.predict(x_test)\n",
    "nlm_lower, nlm_mean, nlm_upper = bh.get_percentile_interval(nlm_posterior_predictive_samples)\n",
    "\n",
    "luna_posterior_predictions, luna_posterior_predictive_samples = luna.predict(x_test)\n",
    "luna_lower, luna_mean, luna_upper = bh.get_percentile_interval(luna_posterior_predictive_samples)\n",
    "######################################\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize = (12, 8))\n",
    "\n",
    "# title = f'$f(x) = 0.5x^3 + \\epsilon$,    $\\epsilon$ ~ N(0, {y_noise_variance})\\n'\n",
    "# title += f'Activation function: {activation_fn_type}\\n'\n",
    "# title += f'Width: {width}\\n'\n",
    "# title += f'# Hidden layers: {hidden_layers}\\n'\n",
    "# title += f'# Auxiliary functions: {output_dim}\\n'\n",
    "# title += f'Variance Prior: {prior_variance}\\n'\n",
    "# title += f'Optimized for {num_iterations} iterations with step size {step_size}'\n",
    "# fig.suptitle(title, fontsize = 15)\n",
    "\n",
    "ax[0].plot(x_test, nlm_mean, color='red') # visualize the mean of the posterior predictive\n",
    "ax[0].fill_between(x_test.reshape(-1), nlm_upper, nlm_lower, color='red', alpha=0.4, label='95% Pred. Interval') # visualize the 95% posterior predictive interval\n",
    "ax[0].scatter(x_train, y_train, color='black', label='training data') # visualize the training data\n",
    "ax[0].legend()\n",
    "ax[0].set_title(f'NLM\\nRegularization: {regularization_param_nlm}\\nTime : {nlm_time} seconds')\n",
    "ax[0].set_xlim([-6, 6])\n",
    "ax[0].set_ylim([-120, 120])\n",
    "\n",
    "ax[1].plot(x_test, luna_mean, color='blue') # visualize the mean of the posterior predictive\n",
    "ax[1].fill_between(x_test.reshape(-1), luna_upper, luna_lower, color='blue', alpha=0.4, label='95% Pred. Interval') # visualize the 95% posterior predictive interval\n",
    "ax[1].scatter(x_train, y_train, color='black', label='training data') # visualize the training data\n",
    "ax[1].legend()\n",
    "ax[1].set_title(f'LUNA\\nRegularization: {regularization_param_luna}, Similarity: {similarity_param} \\nTime : {luna_time} seconds')\n",
    "ax[1].set_xlim([-6, 6])\n",
    "ax[1].set_ylim([-120, 120])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00010-f4715184-0c86-4c5d-a0b2-eed831b53633",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "other notes: \n",
    " - trained on 100 points\n",
    " "
   ]
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "e62ba1f2-2f1c-412f-89e7-8b330cf4445e",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
