{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00001-95841569-0783-4946-95fc-911db545dd64",
    "deepnote_cell_type": "code",
    "execution_millis": 1798,
    "execution_start": 1606948460930,
    "output_cleared": false,
    "source_hash": "69f8c1eb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import standard libraries\n",
    "#!pip install autograd\n",
    "from autograd import numpy as np\n",
    "from autograd import grad\n",
    "from autograd.misc.optimizers import adam, sgd\n",
    "from autograd import scipy as sp\n",
    "import autograd.numpy.random as npr\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "# import our libraries\n",
    "import bayes_helpers as bh\n",
    "from utils import generate_data\n",
    "from utils import run_toy_nn\n",
    "from feed_forward import Feedforward\n",
    "from nlm import NLM\n",
    "\n",
    "from optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "df = pd.read_csv(\"HW8_data.csv\")\n",
    "x_train = np.array(df[\"x\"])\n",
    "y_train = np.array(df[\"y\"])\n",
    "\n",
    "# Create a test set\n",
    "x_test = np.linspace(x_train.min()-1,x_train.max()+1,200)\n",
    "\n",
    "x_train = x_train.reshape((1, -1))\n",
    "y_train = y_train.reshape((1, -1))\n",
    "x_test = x_test.reshape((1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot of the training set\n",
    "fig, ax = plt.subplots(figsize = (8,6))\n",
    "ax.scatter(x_train[0], y_train[0])\n",
    "ax.set_xlabel('x', fontsize = 14)\n",
    "ax.set_ylabel('y', fontsize = 14)\n",
    "plt.title('Training Set', fontsize = 18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_points = 50\n",
    "x_train, y_train, x_test = generate_data(number_of_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test optimizers with FeedForward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the relu activation function\n",
    "activation_fn_type = 'relu'\n",
    "activation_fn = lambda x: np.maximum(np.zeros(x.shape), x)\n",
    "\n",
    "\n",
    "# Define the neural network model parameters\n",
    "width = 50\n",
    "hidden_layers = 2\n",
    "input_dim = 1\n",
    "output_dim = 1\n",
    "\n",
    "architecture = {'width': width,\n",
    "               'hidden_layers': hidden_layers,\n",
    "               'input_dim': input_dim,\n",
    "               'output_dim': output_dim,\n",
    "               'activation_fn_type': activation_fn_type,\n",
    "               'activation_fn_params': 'rate=1',\n",
    "               'activation_fn': activation_fn}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###define design choices in gradient descent\n",
    "params = {'step_size':1e-3, \n",
    "          'max_iteration':1000, \n",
    "          'random_restarts':1,\n",
    "          'optimizer':'adam'}\n",
    "rand_state = 0\n",
    "random = np.random.RandomState(rand_state)\n",
    "\n",
    "nn = Feedforward(architecture, random=random)\n",
    "\n",
    "nn.fit(x_train, y_train, params)\n",
    "\n",
    "#predict on the test x-values\n",
    "y_test_pred = nn.forward(nn.weights, x_test)\n",
    "\n",
    "#visualize the function learned by the neural network\n",
    "plt.scatter(x_train.flatten(), y_train.flatten(), color='black', label='data')\n",
    "plt.plot(x_test.flatten(), y_test_pred.flatten(), color='red', label='learned neural network function')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steepest Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set the parameters (use steepest descent as the optimizer)\n",
    "params = {'random_restarts': 3,\n",
    "          'max_iteration': 500,\n",
    "          'optimizer': steepest_descent}\n",
    "\n",
    "# Instantiate the FeedForward object\n",
    "nn = Feedforward(architecture, random=None, weights=None, objective_function=None)\n",
    "\n",
    "# Fit the NN to the training data\n",
    "nn.fit(x_train, y_train, params)\n",
    "\n",
    "# Create predictions\n",
    "predictions = nn.forward(nn.weights, x_test, final_layer_out=False)\n",
    "\n",
    "# Create a plot of the training set\n",
    "fig, ax = plt.subplots(figsize = (8,6))\n",
    "ax.scatter(x_train[0], y_train[0], c='k', label='training set')\n",
    "ax.plot(x_test[0], predictions.flatten(), c='r', label='predictions')\n",
    "ax.set_xlabel('x', fontsize = 14)\n",
    "ax.set_ylabel('y', fontsize = 14)\n",
    "plt.title('Training Set - Steepest Descent', fontsize = 18)\n",
    "ax.legend(fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newton's Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters (use steepest descent as the optimizer)\n",
    "params = {'random_restarts': 3,\n",
    "          'max_iteration': 500,\n",
    "          'optimizer': newton_method}\n",
    "\n",
    "# Instantiate the FeedForward object\n",
    "nn = Feedforward(architecture, random=None, weights=None, objective_function=None)\n",
    "\n",
    "# Fit the NN to the training data\n",
    "nn.fit(x_train, y_train, params)\n",
    "\n",
    "# Create predictions\n",
    "predictions = nn.forward(nn.weights, x_test, final_layer_out=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot of the training set\n",
    "fig, ax = plt.subplots(figsize = (8,6))\n",
    "ax.scatter(x_train[0], y_train[0], c='k', label='training set')\n",
    "ax.plot(x_test[0], predictions.flatten(), c='r', label='predictions')\n",
    "ax.set_xlabel('x', fontsize = 14)\n",
    "ax.set_ylabel('y', fontsize = 14)\n",
    "plt.title('Training Set - Newton\\'s Method', fontsize = 18)\n",
    "ax.legend(fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters (use steepest descent as the optimizer)\n",
    "params = {'random_restarts': 3,\n",
    "          'max_iteration': 5000,\n",
    "          'optimizer': BFGS}\n",
    "\n",
    "# Instantiate the FeedForward object\n",
    "nn = Feedforward(architecture, random=None, weights=None, objective_function=None)\n",
    "\n",
    "# Fit the NN to the training data\n",
    "nn.fit(x_train, y_train, params)\n",
    "\n",
    "# Create predictions\n",
    "predictions = nn.forward(nn.weights, x_test, final_layer_out=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot of the training set\n",
    "fig, ax = plt.subplots(figsize = (8,6))\n",
    "ax.scatter(x_train[0], y_train[0], c='k', label='training set')\n",
    "ax.plot(x_test[0], predictions.flatten(), c='r', label='predictions')\n",
    "ax.set_xlabel('x', fontsize = 14)\n",
    "ax.set_ylabel('y', fontsize = 14)\n",
    "plt.title('Training Set - BFGS', fontsize = 18)\n",
    "ax.legend(fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjugate Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters (use steepest descent as the optimizer)\n",
    "params = {'random_restarts': 3,\n",
    "          'max_iteration': 5000,\n",
    "          'optimizer': conjugate_gradient}\n",
    "\n",
    "# Instantiate the FeedForward object\n",
    "nn = Feedforward(architecture, random=None, weights=None, objective_function=None)\n",
    "\n",
    "# Fit the NN to the training data\n",
    "nn.fit(x_train, y_train, params)\n",
    "\n",
    "# Create predictions\n",
    "predictions = nn.forward(nn.weights, x_test, final_layer_out=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot of the training set\n",
    "fig, ax = plt.subplots(figsize = (8,6))\n",
    "ax.scatter(x_train[0], y_train[0], c='k', label='training set')\n",
    "ax.plot(x_test[0], predictions.flatten(), c='r', label='predictions')\n",
    "ax.set_xlabel('x', fontsize = 14)\n",
    "ax.set_ylabel('y', fontsize = 14)\n",
    "plt.title('Training Set - Conjugate Gradient', fontsize = 18)\n",
    "ax.legend(fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test optimizers with NLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bayes_helpers as bh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the relu activation function\n",
    "activation_fn_type = 'relu'\n",
    "activation_fn = lambda x: np.maximum(np.zeros(x.shape), x)\n",
    "\n",
    "\n",
    "# Define the neural network model parameters\n",
    "width = 100\n",
    "hidden_layers = 2\n",
    "input_dim = 1\n",
    "output_dim = 1\n",
    "\n",
    "architecture = {'width': width,\n",
    "               'hidden_layers': hidden_layers,\n",
    "               'input_dim': input_dim,\n",
    "               'output_dim': output_dim,\n",
    "               'activation_fn_type': activation_fn_type,\n",
    "               'activation_fn_params': 'rate=1',\n",
    "               'activation_fn': activation_fn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the prior variance\n",
    "prior_var = 1.0\n",
    "y_var = 2.0\n",
    "\n",
    "# Initialize the NLM\n",
    "nlm = NLM(prior_var, y_var, architecture, random_state = np.random.RandomState(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steepest Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters\n",
    "params = {'max_iteration':2000, \n",
    "          'random_restarts':3,\n",
    "          'optimizer': steepest_descent}\n",
    "\n",
    "# Fit the NLM to the training set\n",
    "nlm.train(x_train, y_train, params)\n",
    "\n",
    "# Create predictions\n",
    "posterior_predictives, posterior_predictive_samples = nlm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training data, predictions, and 95% CI\n",
    "bh.viz_pp_samples(x_train, y_train,x_test.flatten(),posterior_predictive_samples,\"NLM test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newton's Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters\n",
    "params = {'max_iteration':2000, \n",
    "          'random_restarts':3,\n",
    "          'optimizer': newton_method}\n",
    "\n",
    "# Fit the NLM to the training set\n",
    "nlm.train(x_train, y_train, params)\n",
    "\n",
    "# Create predictions\n",
    "posterior_predictives, posterior_predictive_samples = nlm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training data, predictions, and 95% CI\n",
    "bh.viz_pp_samples(x_train, y_train,x_test.flatten(),posterior_predictive_samples,\"NLM test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters\n",
    "params = {'max_iteration':2000, \n",
    "          'random_restarts':3,\n",
    "          'optimizer': BFGS}\n",
    "\n",
    "# Fit the NLM to the training set\n",
    "nlm.train(x_train, y_train, params)\n",
    "\n",
    "# Create predictions\n",
    "posterior_predictives, posterior_predictive_samples = nlm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training data, predictions, and 95% CI\n",
    "bh.viz_pp_samples(x_train, y_train,x_test.flatten(),posterior_predictive_samples,\"NLM test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjugate Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters\n",
    "params = {'max_iteration':2000, \n",
    "          'random_restarts':3,\n",
    "          'optimizer': conjugate_gradient}\n",
    "\n",
    "# Fit the NLM to the training set\n",
    "nlm.train(x_train, y_train, params)\n",
    "\n",
    "# Create predictions\n",
    "posterior_predictives, posterior_predictive_samples = nlm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training data, predictions, and 95% CI\n",
    "bh.viz_pp_samples(x_train, y_train,x_test.flatten(),posterior_predictive_samples,\"NLM test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00008-bd0b2e89-1b52-4756-8bbb-03afb90b5f1b",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "33298fe9-5c82-4b2a-b4a6-8b8f00fdd090",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
