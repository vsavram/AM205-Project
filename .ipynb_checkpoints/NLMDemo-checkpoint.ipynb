{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-244a20a3-5850-49a8-b3c4-47c8dd90e3f4",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "# AM207 Final Project\n",
    "\n",
    "Paper: *Learned Uncertainty-Aware (LUNA) Bases for Bayesian Regression using Multi-Headed Auxiliary Networks*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-60483c71-d139-4275-a2dd-d5cb90d94d7f",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "207Notes:\n",
    " -  reproduce figure 6 (rows are random restarts, see main paper) with NLM 2 hidden layers 50-50\n",
    " -  new code: plot the priors\n",
    " -  verify in paper, how many iterations were done for this figure, verify data generating process\n",
    " - \n",
    " -  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00001-82b15dd3-3681-4233-b273-015b39362a48",
    "deepnote_cell_type": "code",
    "execution_millis": 0,
    "execution_start": 1607622678968,
    "output_cleared": false,
    "source_hash": "7ff14c81",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from autograd import numpy as np\n",
    "from autograd import grad\n",
    "from autograd.misc.optimizers import adam, sgd\n",
    "from autograd import scipy as sp\n",
    "import autograd.numpy.random as npr\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# our libraries\n",
    "import utils\n",
    "from nlm import NLM\n",
    "from feed_forward import Feedforward\n",
    "import bayes_helpers as bh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-3de52f4a-e308-4308-bb56-64301fc72795",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00002-da662230-83a9-4a83-a071-abb21b920110",
    "deepnote_cell_type": "code",
    "execution_millis": 7,
    "execution_start": 1607622680831,
    "output_cleared": false,
    "source_hash": "d822ff03",
    "tags": []
   },
   "outputs": [],
   "source": [
    "number_of_points = 50\n",
    "x_train, y_train, x_test = utils.generate_data(number_of_points)\n",
    "\n",
    "x_train = x_train.reshape((1, -1))\n",
    "y_train = y_train.reshape((1, -1))\n",
    "x_test = x_test.reshape((1, -1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-e690ac55-0562-4a71-8cb1-296aa46250bb",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### Define NN Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00004-6632e33c-4eea-427c-9d17-87c54912c224",
    "deepnote_cell_type": "code",
    "execution_millis": 1,
    "execution_start": 1607622832236,
    "output_cleared": false,
    "source_hash": "26470139",
    "tags": []
   },
   "outputs": [],
   "source": [
    "###relu activation\n",
    "activation_fn_type = 'relu'\n",
    "activation_fn = lambda x: np.maximum(np.zeros(x.shape), x)\n",
    "\n",
    "\n",
    "###neural network model design choices\n",
    "width = 50\n",
    "hidden_layers = 2\n",
    "input_dim = 1\n",
    "output_dim = 1\n",
    "\n",
    "architecture = {'width': width,\n",
    "               'hidden_layers': hidden_layers,\n",
    "               'input_dim': input_dim,\n",
    "               'output_dim': output_dim,\n",
    "               'activation_fn_type': 'relu',\n",
    "               'activation_fn_params': 'rate=1',\n",
    "               'activation_fn': activation_fn}\n",
    "\n",
    "#set random state to make the experiments replicable\n",
    "rand_state = 0\n",
    "random = np.random.RandomState(rand_state)\n",
    "\n",
    "###define design choices in gradient descent\n",
    "params = {'step_size':1e-3, \n",
    "          'max_iteration':5000, \n",
    "          'random_restarts':1,\n",
    "          'optimizer':'adam'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00006-092dfa6a-3262-4a8f-b4b1-f07a67eeacc6",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Run Vanilla Nueral Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00005-9ecfb438-c35a-48c3-b29e-107f9e825364",
    "deepnote_cell_type": "code",
    "execution_millis": 10757,
    "execution_start": 1607622834787,
    "output_cleared": false,
    "source_hash": "ec141069",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iteration 2900 lower bound 9.89253584966715; gradient mag: 15.41839892632538633"
     ]
    }
   ],
   "source": [
    "nn = Feedforward(architecture, random=random)\n",
    "\n",
    "t0 = time.time()\n",
    "#fit my neural network to minimize MSE on the given data\n",
    "nn.fit(x_train, y_train, params)\n",
    "nn_time = np.round(time.time() - t0, 3)\n",
    "\n",
    "print(f\"{nn_time} Seconds\")\n",
    "\n",
    "#predict on the test x-values\n",
    "y_test_pred = nn.forward(nn.weights, x_test)\n",
    "\n",
    "#visualize the function learned by the neural network\n",
    "plt.scatter(x_train.flatten(), y_train.flatten(), color='black', label='data')\n",
    "plt.plot(x_test.flatten(), y_test_pred.flatten(), color='red', label='learned neural network function')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "#utils.run_toy_nn(Feedforward,architecture,params,random,x_train,y_train,x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00008-3ff41d87-f57f-4dfb-a174-cde811f0ea9a",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### NLM Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00000-f0eaac6f-fe09-47ff-8d9b-6b57b7ca5d3e",
    "deepnote_cell_type": "code",
    "execution_millis": 3,
    "execution_start": 1607622847361,
    "output_cleared": false,
    "source_hash": "55f9b844",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test\n",
    "prior_var = .1\n",
    "y_var = 1.0\n",
    "regularization_param_nlm = 8.37\n",
    "test_nlm = NLM(prior_var,y_var, regularization_param_nlm,architecture, random_state = np.random.RandomState(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00005-3b5e8825-04a1-4a79-80e0-44a0bbabf7d5",
    "deepnote_cell_type": "code",
    "execution_millis": 529103,
    "execution_start": 1607622858999,
    "output_cleared": false,
    "source_hash": "d851cdec",
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {'step_size':1e-3, \n",
    "          'max_iteration':500, \n",
    "          'random_restarts':1,\n",
    "          'optimizer':'adam'}\n",
    "\n",
    "t0 = time.time()\n",
    "test_nlm.train(x_train,y_train, params)\n",
    "nlm_time = np.round(time.time() - t0, 3)\n",
    "print(f\"{nlm_time} Seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00011-1e248a0b-2711-4319-a408-190b228796be",
    "deepnote_cell_type": "code",
    "execution_millis": 52,
    "execution_start": 1607623388108,
    "output_cleared": false,
    "source_hash": "c1a17f3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "posterior_predictives, posterior_predictive_samples = test_nlm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00013-c0577f9a-c72e-4bbb-8ab5-0eb12eb64c22",
    "deepnote_cell_type": "code",
    "execution_millis": 243,
    "execution_start": 1607623388163,
    "output_cleared": false,
    "source_hash": "2d84a433",
    "tags": []
   },
   "outputs": [],
   "source": [
    "bh.viz_pp_samples(x_train, y_train,x_test.flatten(),posterior_predictive_samples,\"NLM test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00007-428f1ef5-6ef4-4dcd-9d06-80ed7399fdef",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Michael Scratch code for debugging finite differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00007-e1902ccb-b6c1-4e9c-a492-0acef883ea4f",
    "deepnote_cell_type": "code",
    "execution_millis": 3,
    "execution_start": 1606967114743,
    "is_code_hidden": false,
    "output_cleared": false,
    "source_hash": "bdf0f66a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class dumb_NN():\n",
    "\n",
    "    def __init__(self,D_in,D_out,ff):\n",
    "        self.D_in = D_in\n",
    "        self.D_out = D_out\n",
    "        self.ff = ff\n",
    "        \n",
    "    def default_finite_diff(self, W,x):\n",
    "        '''\n",
    "        x.shape[0] is # of dimensions\n",
    "        x.shape[1] is # of observations\n",
    "\n",
    "        output: Returns a 3d matrix:\n",
    "                (in dimension) x (out dimension (# of aux functions)) x (# observations)\n",
    "        '''\n",
    "        \n",
    "        #create one epsilon for each observation\n",
    "        eps = np.random.normal(0,0.1,size=x.shape[1])\n",
    "        #print(eps.shape)\n",
    "\n",
    "        #iterate over features of raw input data (rows of x)\n",
    "        out = np.zeros((self.D_in, self.D_out, x.shape[1]))\n",
    "        #print(out.shape)\n",
    "\n",
    "        #evaluate function at x\n",
    "        f_ex = self.ff.forward(W, x)\n",
    "\n",
    "        #for one dimension at a time\n",
    "        for i in range(x.shape[0]):\n",
    "\n",
    "            delta = np.zeros(x.shape)\n",
    "            delta[i,:] = eps\n",
    "            #print(delta)\n",
    "            f_eps = self.ff.forward(W,x+delta)\n",
    "            print(f_eps.shape)\n",
    "            # out dim X #obs\n",
    "            print(out)\n",
    "            out[i,:,:] = (f_eps - f_ex)/eps # value wise division, different epsilon for each column \n",
    "            print(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def similarity_score(self, W, x):\n",
    "        '''\n",
    "        Calculates total sum of squared cosine similarity between all pairwise combinations of aux \n",
    "        functions\n",
    "        \n",
    "        Inputs: \n",
    "        - W = NumPy array of weights [dim=(1, width H, input dimension D_in)]\n",
    "\n",
    "        Returns:\n",
    "        - score = total cosine similarity squared across all pairs of functions [scalar]\n",
    "\n",
    "        ''' \n",
    "\n",
    "        D_out = self.D_out\n",
    "        score = 0\n",
    "        #derivs of all the aux funcs\n",
    "        holy_grail = self.default_finite_diff(W, x)\n",
    "        # in dim x out dim x # obs\n",
    "        M = holy_grail.shape[1]\n",
    "        for i in range(D_out):\n",
    "            grad_i = holy_grail[:,i,:]\n",
    "            for j in range(i + 1, D_out):\n",
    "                grad_j = holy_grail[:,j,:]\n",
    "                score += self.cos_sim_sq(grad_i, grad_j)\n",
    "        return score\n",
    "\n",
    "    def cos_sim_sq(self,grad_i, grad_j):\n",
    "        numer = np.dot(grad_i, grad_j.T)\n",
    "        denom = (np.dot(grad_i,grad_i.T)*np.dot(grad_j,grad_j.T))\n",
    "        return (numer/denom)[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00008-95c856ca-c7b5-48af-88fd-18d1c64a2908",
    "deepnote_cell_type": "code",
    "execution_millis": 1968,
    "execution_start": 1606965387750,
    "is_code_hidden": false,
    "output_cleared": false,
    "source_hash": "adb60593",
    "tags": []
   },
   "outputs": [],
   "source": [
    "    nn = Feedforward(architecture, random=random)\n",
    "\n",
    "    #fit my neural network to minimize MSE on the given data\n",
    "    nn.fit(x_train, y_train, params)\n",
    "\n",
    "    #predict on the test x-values\n",
    "    y_test_pred = nn.forward(nn.weights, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00009-5e853c16-33f7-4e7d-ad19-18dbb5277137",
    "deepnote_cell_type": "code",
    "execution_millis": 0,
    "execution_start": 1606968685278,
    "is_code_hidden": false,
    "output_cleared": false,
    "source_hash": "b2ca61e9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "out = dumb_NN(input_dim,output_dim,nn).default_finite_diff(nn.weights,x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00013-77503acf-56de-41d3-a8b5-cdbfb92155f6",
    "deepnote_cell_type": "code",
    "execution_millis": 2,
    "execution_start": 1605905735712,
    "output_cleared": false,
    "source_hash": "b623e53d",
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00015-5661d42c-e6eb-4d20-b17e-1b0bea0fc4e7",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00015-4e633ba0-1ff6-4a2e-b8b0-dcb4efb5f91f",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "bd9b06a9-900b-4258-b9d3-f28f55059097",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
